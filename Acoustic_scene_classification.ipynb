{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Acoustic scene classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OMX04mnm0bnE8Kq_2VOPR4xMNTupyiQr",
      "authorship_tag": "ABX9TyPouHKs6wn5WJoHokZlUUbC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shayanthrn/Acoustic_scene_classification/blob/main/Acoustic_scene_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA-C-nOrajZ8"
      },
      "source": [
        "#Acoustic scene classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W5j1vphYZ1a"
      },
      "source": [
        "Dataset: IEEE AASP CASA Challenge, Available on: http://dcase.community/challenge2013/task-acoustic-scene-classification\n",
        "<br/>Currently dataset is in my googe drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5zv_ri5qvFQ"
      },
      "source": [
        "!pip install torchaudio\n",
        "!pip install torchsummary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leigR0aSqRuX"
      },
      "source": [
        "##import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnXHPzXOaoRp"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio\n",
        "import os\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np\n",
        "from torchsummary import summary"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXJFrOHawk8W"
      },
      "source": [
        "##global variables and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aipJBiziwpof"
      },
      "source": [
        "class_map = [\"bus\",\"busystreet\",\"office\",\"openairmarket\",\"park\",\"quietstreet\",\"restaurant\",\"supermarket\",\"tube\",\"tubestation\"]\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.0002"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0LMhgk9q9XW"
      },
      "source": [
        "##create dataset class for DCASE2013 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R6c2UXcq_o2"
      },
      "source": [
        "class DCASE13(Dataset):\n",
        "\n",
        "  def __init__(self,path,class_map):\n",
        "    super().__init__()\n",
        "    self.dataset_path = path\n",
        "    self.class_map = class_map\n",
        "    self.sample_rate = 22050\n",
        "    self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    self.n_sample = 661500 # 30 sec of each audio\n",
        "    self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=self.sample_rate,n_fft=1024,hop_length=512,n_mels=96).to(self.device)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.dataset_path))\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    file_name = os.listdir(self.dataset_path)[index]\n",
        "    class_name = file_name.split('0')[0].split('1')[0]\n",
        "    label = class_map.index(class_name)\n",
        "    file_path = os.path.join(self.dataset_path,file_name)\n",
        "    signal, sample_rate = torchaudio.load(filepath=file_path)\n",
        "    signal = signal.to(self.device)\n",
        "    #resample if necessary\n",
        "    if(sample_rate != self.sample_rate):\n",
        "      resampler = torchaudio.transforms.Resample(sample_rate,self.sample_rate).to(self.device)\n",
        "      signal = resampler(signal)\n",
        "    # stereo to mono convert\n",
        "    if(signal.shape[0]>1):\n",
        "      signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "    #adjust lenght\n",
        "\n",
        "    #cut if necessary\n",
        "    if(signal.shape[1]>self.n_sample):\n",
        "      signal = signal [:,:self.n_sample]\n",
        "    #pad if necessary\n",
        "    elif(signal.shape[1]<self.n_sample):\n",
        "      signal = nn.functional.pad(signal,(0,self.n_sample-signal.shape[1])) #right pad at last dim\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "    signal = self.mel_spectrogram(signal)\n",
        "    return signal,label\n",
        "\n",
        "\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doP3YyPA109d"
      },
      "source": [
        "## create our model which is a CNN\n",
        "<Br />\n",
        "architecture --> 4 Convolutional layer + relu activation + max pooling, flatten,linear, soft max\n",
        "<br /> kernel for Convolutional : 3x3,  kernel for max pooling: 2x2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JA62ok_10nX"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=16,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=16,\n",
        "            out_channels=32,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=32,\n",
        "            out_channels=64,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv4 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=64,\n",
        "            out_channels=128,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.flat = nn.Flatten()\n",
        "    self.linear = nn.Linear(\n",
        "        in_features = 128*7*82,\n",
        "        out_features = 10\n",
        "    )\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self,input):\n",
        "    x = self.conv1(input)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.flat(x)\n",
        "    x = self.linear(x)\n",
        "    predict = self.softmax(x)\n",
        "    return predict"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB1O1Hbh8rdm",
        "outputId": "b536c3da-b26c-445f-8c14-3be31de931e1"
      },
      "source": [
        "cnn = CNN().to(DEVICE)\n",
        "summary(cnn, (1, 96, 1292))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 98, 1294]             160\n",
            "              ReLU-2         [-1, 16, 98, 1294]               0\n",
            "         MaxPool2d-3          [-1, 16, 49, 647]               0\n",
            "            Conv2d-4          [-1, 32, 51, 649]           4,640\n",
            "              ReLU-5          [-1, 32, 51, 649]               0\n",
            "         MaxPool2d-6          [-1, 32, 25, 324]               0\n",
            "            Conv2d-7          [-1, 64, 27, 326]          18,496\n",
            "              ReLU-8          [-1, 64, 27, 326]               0\n",
            "         MaxPool2d-9          [-1, 64, 13, 163]               0\n",
            "           Conv2d-10         [-1, 128, 15, 165]          73,856\n",
            "             ReLU-11         [-1, 128, 15, 165]               0\n",
            "        MaxPool2d-12           [-1, 128, 7, 82]               0\n",
            "          Flatten-13                [-1, 73472]               0\n",
            "           Linear-14                   [-1, 10]         734,730\n",
            "          Softmax-15                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 831,882\n",
            "Trainable params: 831,882\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.47\n",
            "Forward/backward pass size (MB): 68.55\n",
            "Params size (MB): 3.17\n",
            "Estimated Total Size (MB): 72.20\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrMEf3NzBRLt"
      },
      "source": [
        "## Train Function\n",
        "<br /> optimizer:adam, loss function: crossentropy, batch size: 32, epochs: 20, learning rate: 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EI0O2pvB1Tk"
      },
      "source": [
        "def train_one_epoch(model,dataloader,optimizer,loss_f,device):\n",
        "\n",
        "  for signal, label in dataloader:\n",
        "\n",
        "    signal, label = signal.to(device), label.to(device)\n",
        "    output = model(signal)\n",
        "    loss = loss_f(output,label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"loss after this epoch: {loss.item()}\")\n",
        "\n",
        "def train(model,dataloader,optimizer,loss_f,device,epochs):\n",
        "  model.train()\n",
        "  for i in range(epochs):\n",
        "    print(f\" Epoch: {i+1}\")\n",
        "    train_one_epoch(model,dataloader,optimizer,loss_f,device)\n",
        "    print(\"----------------------\")"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QJXITA9OCLN"
      },
      "source": [
        "##Final Result:\n",
        "<br/>\n",
        "model accuracy:<br/>\n",
        "batch size:50,Lr:0.0001,epochs:20, n_mels:64, duration: 10sec --> 68%<br/> \n",
        "batch size:50,Lr:0.0001,epochs:100, n_mels:64, duration: 10sec --> 67%<br/> \n",
        "batch size:50,Lr:0.0001,epochs:130, n_mels:64, duration: 10sec --> 74%<br/> \n",
        "batch size:50,Lr:0.0002,epochs:50, n_mels:64, duration: 10sec --> 77%<br/> \n",
        "batch size:32,Lr:0.0002,epochs:50, n_mels:96, duration: 15sec --> 86%<br/> batch size:32,Lr:0.0002,epochs:50, n_mels:96, duration: 30sec --> 70%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPLeNuNNtfg"
      },
      "source": [
        "##personal tests and getting result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PlRuUeH1r2T"
      },
      "source": [
        "dcase13 = DCASE13(\"/content/drive/MyDrive/IEEE_AASP_CASA_Challenge/DCASE13_train\",class_map)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmnJnjd22d2L"
      },
      "source": [
        "dataloader = DataLoader(dcase13 , batch_size=BATCH_SIZE , shuffle=True)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woSO6yKaDv-s"
      },
      "source": [
        "optimizer = torch.optim.Adam(cnn.parameters(),lr=LEARNING_RATE)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aLqolgMEGgL"
      },
      "source": [
        "loss_f = nn.CrossEntropyLoss()"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca_xjLwCERHS",
        "outputId": "e9206913-6f51-4c10-c818-6933a1e7a776"
      },
      "source": [
        "print(f\"we are using {DEVICE}\")\n",
        "train(cnn,dataloader,optimizer,loss_f,DEVICE,EPOCHS)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we are using cuda\n",
            " Epoch: 1\n",
            "loss after this epoch: 2.328824996948242\n",
            "----------------------\n",
            " Epoch: 2\n",
            "loss after this epoch: 2.3045663833618164\n",
            "----------------------\n",
            " Epoch: 3\n",
            "loss after this epoch: 2.010098934173584\n",
            "----------------------\n",
            " Epoch: 4\n",
            "loss after this epoch: 2.020603895187378\n",
            "----------------------\n",
            " Epoch: 5\n",
            "loss after this epoch: 1.8490681648254395\n",
            "----------------------\n",
            " Epoch: 6\n",
            "loss after this epoch: 2.0560996532440186\n",
            "----------------------\n",
            " Epoch: 7\n",
            "loss after this epoch: 2.091836452484131\n",
            "----------------------\n",
            " Epoch: 8\n",
            "loss after this epoch: 1.9683080911636353\n",
            "----------------------\n",
            " Epoch: 9\n",
            "loss after this epoch: 1.7442511320114136\n",
            "----------------------\n",
            " Epoch: 10\n",
            "loss after this epoch: 1.6076536178588867\n",
            "----------------------\n",
            " Epoch: 11\n",
            "loss after this epoch: 1.465901494026184\n",
            "----------------------\n",
            " Epoch: 12\n",
            "loss after this epoch: 1.4629019498825073\n",
            "----------------------\n",
            " Epoch: 13\n",
            "loss after this epoch: 1.8425918817520142\n",
            "----------------------\n",
            " Epoch: 14\n",
            "loss after this epoch: 1.9385898113250732\n",
            "----------------------\n",
            " Epoch: 15\n",
            "loss after this epoch: 1.6427581310272217\n",
            "----------------------\n",
            " Epoch: 16\n",
            "loss after this epoch: 1.4750008583068848\n",
            "----------------------\n",
            " Epoch: 17\n",
            "loss after this epoch: 1.5326536893844604\n",
            "----------------------\n",
            " Epoch: 18\n",
            "loss after this epoch: 1.6651359796524048\n",
            "----------------------\n",
            " Epoch: 19\n",
            "loss after this epoch: 2.0441336631774902\n",
            "----------------------\n",
            " Epoch: 20\n",
            "loss after this epoch: 1.5475374460220337\n",
            "----------------------\n",
            " Epoch: 21\n",
            "loss after this epoch: 1.5039554834365845\n",
            "----------------------\n",
            " Epoch: 22\n",
            "loss after this epoch: 1.5262537002563477\n",
            "----------------------\n",
            " Epoch: 23\n",
            "loss after this epoch: 1.6759765148162842\n",
            "----------------------\n",
            " Epoch: 24\n",
            "loss after this epoch: 1.4612276554107666\n",
            "----------------------\n",
            " Epoch: 25\n",
            "loss after this epoch: 1.6835339069366455\n",
            "----------------------\n",
            " Epoch: 26\n",
            "loss after this epoch: 1.4611601829528809\n",
            "----------------------\n",
            " Epoch: 27\n",
            "loss after this epoch: 1.5356990098953247\n",
            "----------------------\n",
            " Epoch: 28\n",
            "loss after this epoch: 1.4611520767211914\n",
            "----------------------\n",
            " Epoch: 29\n",
            "loss after this epoch: 1.461245059967041\n",
            "----------------------\n",
            " Epoch: 30\n",
            "loss after this epoch: 1.462333083152771\n",
            "----------------------\n",
            " Epoch: 31\n",
            "loss after this epoch: 1.4611515998840332\n",
            "----------------------\n",
            " Epoch: 32\n",
            "loss after this epoch: 1.704437017440796\n",
            "----------------------\n",
            " Epoch: 33\n",
            "loss after this epoch: 1.5204250812530518\n",
            "----------------------\n",
            " Epoch: 34\n",
            "loss after this epoch: 1.694435954093933\n",
            "----------------------\n",
            " Epoch: 35\n",
            "loss after this epoch: 1.461151123046875\n",
            "----------------------\n",
            " Epoch: 36\n",
            "loss after this epoch: 1.4613428115844727\n",
            "----------------------\n",
            " Epoch: 37\n",
            "loss after this epoch: 1.4703950881958008\n",
            "----------------------\n",
            " Epoch: 38\n",
            "loss after this epoch: 1.7111501693725586\n",
            "----------------------\n",
            " Epoch: 39\n",
            "loss after this epoch: 1.4611515998840332\n",
            "----------------------\n",
            " Epoch: 40\n",
            "loss after this epoch: 1.5480509996414185\n",
            "----------------------\n",
            " Epoch: 41\n",
            "loss after this epoch: 1.4897743463516235\n",
            "----------------------\n",
            " Epoch: 42\n",
            "loss after this epoch: 1.461151361465454\n",
            "----------------------\n",
            " Epoch: 43\n",
            "loss after this epoch: 1.626913070678711\n",
            "----------------------\n",
            " Epoch: 44\n",
            "loss after this epoch: 1.8136290311813354\n",
            "----------------------\n",
            " Epoch: 45\n",
            "loss after this epoch: 1.961233139038086\n",
            "----------------------\n",
            " Epoch: 46\n",
            "loss after this epoch: 1.7211803197860718\n",
            "----------------------\n",
            " Epoch: 47\n",
            "loss after this epoch: 1.9612047672271729\n",
            "----------------------\n",
            " Epoch: 48\n",
            "loss after this epoch: 1.7111502885818481\n",
            "----------------------\n",
            " Epoch: 49\n",
            "loss after this epoch: 1.9102284908294678\n",
            "----------------------\n",
            " Epoch: 50\n",
            "loss after this epoch: 1.4611501693725586\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSwTUZUAEQEU"
      },
      "source": [
        "torch.save(cnn.state_dict(), \"model.pth\")"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf7OWsMlG-cC"
      },
      "source": [
        "dcase13_test = DCASE13(\"/content/drive/MyDrive/IEEE_AASP_CASA_Challenge/DCASE13_eval\",class_map)\n",
        "dataloader_test = DataLoader(dcase13 , batch_size=BATCH_SIZE , shuffle=True)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-E1bB6eHGmR",
        "outputId": "5c286195-4863-44a9-fe46-523dfbdc08fb"
      },
      "source": [
        "correct = 0\n",
        "total = 100\n",
        "for input, label in dataloader_test:\n",
        "  batchlabel = label\n",
        "  batchpredict = cnn(input).argmax(dim=1)\n",
        "  for i in range(len(batchlabel)):\n",
        "    if(batchpredict[i].item()==batchlabel[i].item()):\n",
        "      correct+=1\n",
        "\n",
        "print(f\" Acurracy after {EPOCHS} epoch : {correct/total}\")"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Acurracy after 50 epoch : 0.7\n"
          ]
        }
      ]
    }
  ]
}